{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Create Function And Pydantic Modals To Control The Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Pydantic Modals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models layer\n",
    "from pydantic import BaseModel, model_validator\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "# Validator functions\n",
    "def validate_latitude(v: float) -> float:\n",
    "    assert -90 <= v <= 90, 'Invalid latitude'\n",
    "    return v\n",
    "\n",
    "def validate_longitude(v: float) -> float:\n",
    "    assert -180 <= v <= 180, 'Invalid longitude'\n",
    "    return v\n",
    "\n",
    "# Annotated types\n",
    "Latitude = Annotated[float, validate_latitude]\n",
    "Longitude = Annotated[float, validate_longitude]\n",
    "\n",
    "# Pydantic models\n",
    "class MapState(BaseModel):\n",
    "    latitude: Latitude\n",
    "    longitude: Longitude\n",
    "    zoom: float\n",
    "\n",
    "class MarkersState(BaseModel):\n",
    "    latitudes: list[Latitude]\n",
    "    longitudes: list[Longitude]\n",
    "    labels: list[str]\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    def validate_marker_length(self):\n",
    "        if len(self.latitudes) != len(self.longitudes) or len(self.latitudes) != len(self.labels):\n",
    "            raise ValueError(\n",
    "                \"Latitudes, longitudes, and labels must have the same number of elements\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Function To Get Updated Map Coordindates and an inital Map State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data layer\n",
    "from typing import Optional, Any\n",
    "from pydantic import ValidationError\n",
    "\n",
    "# Initial map state with class instances\n",
    "ai_powered_map: dict[str, Any] = {\n",
    "    \"map_state\": MapState(latitude=39.949610, longitude=75.150282, zoom=16).model_dump(),\n",
    "    \"markers_state\": MarkersState(latitudes=[], longitudes=[], labels=[]).model_dump()\n",
    "}\n",
    "\n",
    "# Function to update map and markers\n",
    "def update_map_and_markers(\n",
    "    map_state: Optional[MapState] = None,\n",
    "    markers_state: Optional[MarkersState] = None\n",
    ") -> dict[str, Any]:\n",
    "\n",
    "    response_format = {\"status\": \"\", \"values\": ai_powered_map}\n",
    "    try:\n",
    "        if map_state is not None:\n",
    "            ai_powered_map[\"map_state\"] = map_state.model_dump()\n",
    "\n",
    "        if markers_state is not None:\n",
    "            ai_powered_map[\"markers_state\"] = markers_state.model_dump()\n",
    "\n",
    "        response_format[\"status\"] = \"Map location and markers updated Now continue answering my last question\"\n",
    "\n",
    "    except ValidationError as e:\n",
    "        response_format[\"status\"] = f\"Error update map: {\n",
    "            e}, continue answering my last question\"\n",
    "\n",
    "    return response_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Building the Open AI Streaming Travel AI Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. OpenAI Schema for the Function & Base Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.shared_params import FunctionDefinition\n",
    "\n",
    "map_ai_control_schema = FunctionDefinition(\n",
    "    name=\"update_map_and_markers\",\n",
    "    description=\"Update map to center on a particular location and add list of markers to the map\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"longitude\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Longitude of the location to center the map on\"\n",
    "            },\n",
    "            \"latitude\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Latitude of the location to center the map on\"\n",
    "            },\n",
    "            \"zoom\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Zoom level of the map\"\n",
    "            },\n",
    "            \"longitudes\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"number\"\n",
    "                },\n",
    "                \"description\": \"List of longitudes for each marker\"\n",
    "            },\n",
    "            \"latitudes\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"number\"\n",
    "                },\n",
    "                \"description\": \"List of latitudes for each marker\"\n",
    "            },\n",
    "            \"labels\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"description\": \"List of labels for each marker\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"longitude\", \"latitude\", \"zoom\", \"longitudes\", \"latitudes\", \"labels\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat.chat_completion_tool_param import ChatCompletionToolParam\n",
    "\n",
    "map_ai_control_tool: ChatCompletionToolParam = ChatCompletionToolParam(\n",
    "    function=map_ai_control_schema, type=\"function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Map the received name to the function\n",
    "available_functions = {\n",
    "    \"update_map_and_markers\": update_map_and_markers,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed Prompt\n",
    "BASE_PROMPT: str = \"\"\"You are an AI Travel Assistant who make global travellers traval planning fun and interactive:\n",
    "\n",
    "Before replying perform the following steps:\n",
    "\n",
    "1. If user share any travel location name, update the map to go to that place and Add markers on the place.\n",
    "2. if user shared any travel suggestions update them map.\n",
    "\n",
    "If user sends any general message share with them you are a helpful AI Travel Assistant and you can help them with travel planning.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data layer to manage chat_history\n",
    "import shelve\n",
    "\n",
    "class Database:\n",
    "    def __init__(self, dbName: str = \"chat_history\") -> None:\n",
    "        self.dbName = dbName\n",
    "\n",
    "    # Load chat history from shelve file\n",
    "    def load_chat_history(self) -> [dict]:\n",
    "        with shelve.open(self.dbName) as db:\n",
    "            return db.get(\"messages\", [{\"role\": \"system\", \"content\": BASE_PROMPT}])\n",
    "\n",
    "    # Save chat history to shelve file\n",
    "\n",
    "    def save_chat_history(self, messages: [dict]):\n",
    "        print(\"Database: Save\", messages)\n",
    "        with shelve.open(self.dbName) as db:\n",
    "            db[\"messages\"] = messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Layer \n",
    "\n",
    "# A Class to Call the Assistant, Stream Text and Function Calling and send the final response back\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "from typing import Any\n",
    "from openai import Stream\n",
    "from openai.types.chat.chat_completion_chunk import ChatCompletionChunk\n",
    "# Service Layer\n",
    "\n",
    "# A Class to Call the Assistant, Stream Text and Function Calling and send the final response back\n",
    "class OpenAITravelBotModel:\n",
    "    def __init__(self, name: str, model: str = \"gpt-3.5-turbo-1106\") -> None:\n",
    "        self.name: str = name\n",
    "        self.model: str = model\n",
    "        load_dotenv(find_dotenv())\n",
    "        self.client: OpenAI = OpenAI()\n",
    "        self.db: Database = Database()\n",
    "        self.messages = self.load_chat_history()\n",
    "        self.map_control_values = ai_powered_map\n",
    "\n",
    "    def load_chat_history(self) -> []:\n",
    "        return self.db.load_chat_history()\n",
    "\n",
    "    def save_chat_history(self):\n",
    "        # print(\"Model: Save\", self.messages)\n",
    "        self.db.save_chat_history(messages=self.messages)\n",
    "\n",
    "    def delete_chat_history(self):\n",
    "        print(\"Model: Delete\")\n",
    "        self.messages = [{\"role\": \"system\", \"content\": BASE_PROMPT}]\n",
    "        self.save_chat_history()\n",
    "\n",
    "    def get_messages(self) -> [dict]:\n",
    "        return self.messages\n",
    "\n",
    "    def append_message(self, message: dict):\n",
    "        self.messages.append(message)\n",
    "\n",
    "    def get_map_control_values(self):\n",
    "        return self.map_control_values\n",
    "\n",
    "    def send_message(self, message: dict | None = None, append_message: bool = True, include_func_messages: bool = False, func_message_list: list[dict] | None = None) -> Any:\n",
    "        # Appending our own message to the chat history\n",
    "        if append_message and message is not None:\n",
    "            self.append_message(message=message)\n",
    "\n",
    "        # We will not include the function calling cycle message in our chat array i.e Assistant : Call Function | User: Complted\n",
    "        if include_func_messages and func_message_list is not None:\n",
    "            combined_list = self.messages + func_message_list\n",
    "            message_stream = combined_list\n",
    "            # print(\"Combined message_stream\", message_stream)\n",
    "        else:\n",
    "            message_stream = self.messages\n",
    "            # print(\"Regular message_stream\", message_stream)\n",
    "\n",
    "\n",
    "        stream: Stream[ChatCompletionChunk] = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=message_stream,\n",
    "            stream=True,\n",
    "            tools=[map_ai_control_tool],\n",
    "        )\n",
    "        return stream\n",
    "\n",
    "\n",
    "    def run_streaming_assistant(self, prompt: str):\n",
    "        response_stream = self.send_message(\n",
    "            {\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        current_tool_name = None\n",
    "        accumulated_args = \"\"\n",
    "\n",
    "        for message in response_stream:\n",
    "            response_message = message.choices[0].delta\n",
    "\n",
    "            if response_message.content:\n",
    "                yield response_message.content\n",
    "            elif response_message.tool_calls:\n",
    "                for tool_call in response_message.tool_calls:\n",
    "                    tool_function = tool_call.function\n",
    "\n",
    "                    if tool_function:\n",
    "                        if tool_function.name:\n",
    "                            if current_tool_name:\n",
    "                                # Process the previous tool call before starting a new one\n",
    "                                yield self.process_streaming_tool_call(current_tool_name, accumulated_args)\n",
    "\n",
    "                            current_tool_name = tool_function.name\n",
    "                            accumulated_args = tool_function.arguments\n",
    "                        else:\n",
    "                            # Append fragment to the accumulated arguments string\n",
    "                            accumulated_args += tool_function.arguments\n",
    "\n",
    "        # Process the last tool call if it exists\n",
    "        if current_tool_name:\n",
    "            function_call_response = self.process_streaming_tool_call(\n",
    "                current_tool_name, accumulated_args)\n",
    "\n",
    "            # Calling OpenAI Again to get the final response\n",
    "            print(\"Calling OpenAI Again to get the final response\")\n",
    "            second_response_stream = self.send_message(\n",
    "                message=None,\n",
    "                append_message=False,\n",
    "                include_func_messages=True,\n",
    "                func_message_list=[{\"role\": \"assistant\", \"content\": f'Call {current_tool_name} with arguments: {accumulated_args}'}, {\"role\": \"user\", \"content\": function_call_response}]\n",
    "\n",
    "            )\n",
    "            for message in second_response_stream:\n",
    "                response_message = message.choices[0].delta\n",
    "\n",
    "                if response_message.content:\n",
    "                    print(\"response_message\", response_message.content)\n",
    "                    yield response_message.content\n",
    "\n",
    "        # Signal the end of the stream\n",
    "        yield \"__END__\"\n",
    "\n",
    "    def process_streaming_tool_call(self, tool_name, args_str):\n",
    "        print(f\"Processed {tool_name} with arguments: {args_str}\")\n",
    "        # Append the tool call to the chat history - assistant response\n",
    "        # self.messages.append({\"role\": \"assistant\", \"content\": f'Call {tool_name} with arguments: {args_str}'})\n",
    "\n",
    "        try:\n",
    "            # Parse the argument string into a dictionary\n",
    "            args = json.loads(args_str)\n",
    "            function_to_call = available_functions[tool_name]\n",
    "\n",
    "            map_state: MapState | None = None\n",
    "            markers_state: MarkersState | None = None\n",
    "\n",
    "            # Create MapState object if map-related args are present\n",
    "            if 'latitude' in args and 'longitude' in args and 'zoom' in args:\n",
    "                map_state = MapState(\n",
    "                    latitude=args['latitude'],\n",
    "                    longitude=args['longitude'],\n",
    "                    zoom=args['zoom']\n",
    "                )\n",
    "                # print (\"map_state\", map_state)\n",
    "\n",
    "            # Create MarkersState object if marker-related args are present\n",
    "            if 'latitudes' in args and 'longitudes' in args and 'labels' in args:\n",
    "                markers_state = MarkersState(\n",
    "                    latitudes=args['latitudes'],\n",
    "                    longitudes=args['longitudes'],\n",
    "                    labels=args['labels']\n",
    "                )\n",
    "\n",
    "                print\n",
    "\n",
    "            update_map_res = function_to_call(\n",
    "                map_state=map_state,\n",
    "                markers_state=markers_state\n",
    "            )\n",
    "\n",
    "            print(\"map_update_call\", update_map_res['status'])\n",
    "            # print (\"map_update_call\", update_map_res['values'])\n",
    "            self.map_control_values = update_map_res['values']\n",
    "\n",
    "            return update_map_res['status']\n",
    "\n",
    "        except KeyError:\n",
    "            return f\"Error: {tool_name} is not a valid tool name\"\n",
    "\n",
    "        except ValidationError as e:\n",
    "            return f\"Error: {e}\"\n",
    "\n",
    "        except AssertionError as e:\n",
    "            return f\"Error: {e}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map_state': {'latitude': 39.94961, 'longitude': 75.150282, 'zoom': 16.0},\n",
       " 'markers_state': {'latitudes': [], 'longitudes': [], 'labels': []}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_powered_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing The OpenAITravelBotModel Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = OpenAITravelBotModel(\"My Travel Assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_streaming_travel_ai(prompt: str):\n",
    "    # Collect Streaming CHunks for modal Response\n",
    "    complete_response = \"\"\n",
    "\n",
    "    # Example usage\n",
    "    for response in bot.run_streaming_assistant(prompt):\n",
    "        #  We will get chunks of response from the assistant and will stream it in web layer.\n",
    "        yield (response)\n",
    "        if response == \"__END__\":\n",
    "            break\n",
    "        complete_response += response  # Accumulate the response\n",
    "\n",
    "    print('complete_response', complete_response)\n",
    "    bot.messages.append({\"role\": \"assistant\", \"content\": complete_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed update_map_and_markers with arguments: {\"longitude\":101.6869,\"latitude\":3.139,\"zoom\":12,\"longitudes\":[101.6869],\"latitudes\":[3.139],\"labels\":[\"Kuala Lumpur\"]}\n",
      "map_update_call Map location and markers updated Now continue answering my last question\n",
      "Calling OpenAI Again to get the final response\n",
      "response_message As\n",
      "As\n",
      "response_message  an\n",
      " an\n",
      "response_message  AI\n",
      " AI\n",
      "response_message  Travel\n",
      " Travel\n",
      "response_message  Assistant\n",
      " Assistant\n",
      "response_message ,\n",
      ",\n",
      "response_message  I\n",
      " I\n",
      "response_message 'm\n",
      "'m\n",
      "response_message  here\n",
      " here\n",
      "response_message  to\n",
      " to\n",
      "response_message  help\n",
      " help\n",
      "response_message  you\n",
      " you\n",
      "response_message  with\n",
      " with\n",
      "response_message  travel\n",
      " travel\n",
      "response_message  planning\n",
      " planning\n",
      "response_message  and\n",
      " and\n",
      "response_message  any\n",
      " any\n",
      "response_message  questions\n",
      " questions\n",
      "response_message  you\n",
      " you\n",
      "response_message  have\n",
      " have\n",
      "response_message  about\n",
      " about\n",
      "response_message  your\n",
      " your\n",
      "response_message  travel\n",
      " travel\n",
      "response_message  destinations\n",
      " destinations\n",
      "response_message .\n",
      ".\n",
      "response_message  Feel\n",
      " Feel\n",
      "response_message  free\n",
      " free\n",
      "response_message  to\n",
      " to\n",
      "response_message  ask\n",
      " ask\n",
      "response_message  me\n",
      " me\n",
      "response_message  anything\n",
      " anything\n",
      "response_message  related\n",
      " related\n",
      "response_message  to\n",
      " to\n",
      "response_message  travel\n",
      " travel\n",
      "response_message ,\n",
      ",\n",
      "response_message  and\n",
      " and\n",
      "response_message  I\n",
      " I\n",
      "response_message 'll\n",
      "'ll\n",
      "response_message  be\n",
      " be\n",
      "response_message  happy\n",
      " happy\n",
      "response_message  to\n",
      " to\n",
      "response_message  assist\n",
      " assist\n",
      "response_message  you\n",
      " you\n",
      "response_message !\n",
      "!\n",
      "__END__\n",
      "complete_response As an AI Travel Assistant, I'm here to help you with travel planning and any questions you have about your travel destinations. Feel free to ask me anything related to travel, and I'll be happy to assist you!\n"
     ]
    }
   ],
   "source": [
    "for part_res in openai_streaming_travel_ai(\"Show Kulala Lumpur on Map\"):\n",
    "        # Put each character into the queue\n",
    "        print(part_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map_state': {'latitude': 3.139, 'longitude': 101.6869, 'zoom': 12.0},\n",
       " 'markers_state': {'latitudes': [3.139],\n",
       "  'longitudes': [101.6869],\n",
       "  'labels': ['Kuala Lumpur']}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.get_map_control_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Functions to Create Seamless AI Travel Agent Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Get Map Control Values\n",
    "def get_map_coordinates():\n",
    "    return bot.get_map_control_values()\n",
    "\n",
    "\n",
    "# b. Save Current Response to Database (Shelf currently)\n",
    "def save_chat_to_db():\n",
    "    return bot.save_chat_history()\n",
    "\n",
    "\n",
    "# c. Get Database Chat (Shelf currently)\n",
    "def load_database_chat_history():\n",
    "    return bot.load_chat_history()\n",
    "\n",
    "\n",
    "# d. Get All Messages Present In Class Instance\n",
    "def get_all_messages():\n",
    "    return bot.get_messages()\n",
    "    \n",
    "def delete_chat_history():\n",
    "    return bot.delete_chat_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AI Powered Map Interactions using Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whenever we call the bot.run_streaming_assistant() function, it will return a generator that yields the assistantâ€™s responses as they come in. \n",
    "\n",
    "We can then use these responses to update the chat interface. Function Calling is determined and completed by the OpenAI llm. And after which the ai_powered_map state is updated\n",
    "\n",
    "Now let's plot the maps using Plotly and create a function that response and then updated the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function To Plot and Update the Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from typing import Union\n",
    "\n",
    "# Function to create and display the map\n",
    "def create_map(map_state: dict[str, Union[float, str]], markers_state: dict[str, list[Union[float, str]]]) -> None:\n",
    "    \n",
    "    figure = go.Figure(go.Scattermapbox(mode=\"markers\"))\n",
    "    \n",
    "    figure.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color='red', size=14),\n",
    "            lat=markers_state[\"latitudes\"],\n",
    "            lon=markers_state[\"longitudes\"],\n",
    "            text=markers_state[\"labels\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    figure.update_layout(\n",
    "        mapbox=dict(\n",
    "            style=\"open-street-map\",\n",
    "            # accesstoken=MAPBOX_ACCESS_TOKEN, # If you don't have MAPBOX token, replace with style=\"open-street-map\".\n",
    "            center=go.layout.mapbox.Center(\n",
    "                lat=map_state[\"latitude\"],\n",
    "                lon=map_state[\"longitude\"]\n",
    "            ),\n",
    "            zoom=map_state[\"zoom\"]\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, t=0, b=0)\n",
    "    )\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "type": "scattermapbox"
        },
        {
         "lat": [
          3.139
         ],
         "lon": [
          101.6869
         ],
         "marker": {
          "color": "red",
          "size": 14
         },
         "mode": "markers",
         "text": [
          "Kuala Lumpur"
         ],
         "type": "scattermapbox"
        }
       ],
       "layout": {
        "mapbox": {
         "center": {
          "lat": 3.139,
          "lon": 101.6869
         },
         "style": "open-street-map",
         "zoom": 12
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_map(map_state=ai_powered_map['map_state'], markers_state=ai_powered_map['markers_state'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats on building the Streaming Travel AI Assistant Proof of concept proof of concept. Currently the concept is well suited for single user.\n",
    "\n",
    "- We have used shelf to store user messages and create a stateful Travel AI Assistant Experience\n",
    "- For general queries we immediatily start getting the streamed response\n",
    "- For Travel  queries that assistant does Function Calling to update Map Coordianted and returns the Streamed Response.\n",
    "- Finally we have used plotly to visualzie how will AI Powered Map interactions Look like.\n",
    "\n",
    "Now we have the complete code and we can move on designing the FastAPI Microservice. We will use the above plotly map to create AI powered map interactions with streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the Map looks outdated? Go to MapBox, signup and get your access token.\n",
    "\n",
    "Next in the create_map function you can pass this token comment the map-style argument,\n",
    "\n",
    "    figure.update_layout(\n",
    "        mapbox=dict(\n",
    "            accesstoken=MAPBOX_ACCESS_TOKEN, # If you don't have MAPBOX token, replace with style=\"open-street-map\".\n",
    "            center=go.layout.mapbox.Center(\n",
    "                lat=map_state[\"latitude\"],\n",
    "                lon=map_state[\"longitude\"]\n",
    "            ),\n",
    "            zoom=map_state[\"zoom\"]\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, t=0, b=0)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
