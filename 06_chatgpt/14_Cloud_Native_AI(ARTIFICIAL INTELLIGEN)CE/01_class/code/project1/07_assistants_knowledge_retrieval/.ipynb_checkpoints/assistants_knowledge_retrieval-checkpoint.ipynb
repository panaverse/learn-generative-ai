{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants API - Knowledge Retrieval \n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/knowledge-retrieval\n",
    "\n",
    "https://community.openai.com/t/new-assistants-api-a-potential-replacement-for-low-level-rag-style-content-generation/475677 \n",
    "\n",
    "Watch:\n",
    "\n",
    "https://youtu.be/5rcjGjgJNQc?t=600&si=d9OtX0nMi2Rv0fQV \n",
    "\n",
    "References:\n",
    "\n",
    "https://community.openai.com/t/assistants-api-retrieval-pricing-how-much-does-this-cost/485188/8\n",
    "\n",
    "https://medium.com/madhukarkumar/what-does-openais-announcement-mean-for-retrieval-augmented-generation-rag-and-vector-only-54bfc34cba2c\n",
    "\n",
    "https://www.youtube.com/watch?v=ClfyQNkTeUc\n",
    "\n",
    "https://www.pinecone.io/learn/assistants-api-canopy/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](ret.jpg \"Assistants\")\n",
    "\n",
    "![Alt text](objects.jpeg \"Assistants_Objects\")\n",
    "\n",
    "https://cobusgreyling.medium.com/openai-assistant-with-retriever-tool-08e9158ca900 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Retrieval\n",
    "\n",
    "Retrieval augments the Assistant with knowledge from outside its model, such as proprietary product information or documents provided by your users. Once a file is uploaded and passed to the Assistant, OpenAI will automatically chunk your documents, index and store the embeddings, and implement vector search to retrieve relevant content to answer user queries.\n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/knowledge-retrieval \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\n",
    "\n",
    "The model then decides when to retrieve content based on the user Messages. The Assistants API automatically chooses between two retrieval techniques:\n",
    "\n",
    "1. it either passes the file content in the prompt for short documents, or\n",
    "2. performs a vector search for longer documents\n",
    "\n",
    "Retrieval currently optimizes for quality by adding all relevant content to the context of model calls. We plan to introduce other retrieval strategies to enable developers to choose a different tradeoff between retrieval quality and model usage cost.\n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/how-it-works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Upload the file and Create an Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-kCbiOyEy7YInespbVKjd3CGC', bytes=48802, created_at=1700222301, filename='zia_profile.pdf', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta import Assistant\n",
    "\n",
    "# Upload a file with an \"assistants\" purpose\n",
    "file = client.files.create(\n",
    "  file=open(\"zia_profile.pdf\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "print(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant: Assistant = client.beta.assistants.create(\n",
    "  name=\"Student Support Assistant\",\n",
    "  instructions=\"You are a student support chatbot. Use your knowledge base to best respond to student queries about Zia U. Khan.\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[{\"type\": \"retrieval\"}],\n",
    "  file_ids=[file.id]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_PWEJVnptC835VBdF5njsY6Qj', created_at=1700222303, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread: Thread  = client.beta.threads.create()\n",
    "\n",
    "print(thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add a Message to a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.thread_message import ThreadMessage\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"When and which city Zia U. Khan was born?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run: Run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Pakistani. The user is the student of PIAIC.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Check the Run status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_mVymK7OEfpxoFYHV6b96GxQS', assistant_id='asst_AWrPlj801RKMzIf2OnpFzgFJ', cancelled_at=None, completed_at=1700222308, created_at=1700222304, expires_at=None, failed_at=None, file_ids=['file-kCbiOyEy7YInespbVKjd3CGC'], instructions='Please address the user as Pakistani. The user is the student of PIAIC.', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=1700222304, status='completed', thread_id='thread_PWEJVnptC835VBdF5njsY6Qj', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "run: Run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "\n",
    "print(run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Display the Assistant's Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: When and which city Zia U. Khan was born?\n",
      "assistant: Zia U. Khan was born in Sialkot in 1961【7†source】.\n"
     ]
    }
   ],
   "source": [
    "# from openai.resources.beta.threads.messages.messages import SyncCursorPage \n",
    "\n",
    "messages: list[ThreadMessage] = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "for m in reversed(messages.data):\n",
    "  print(m.role + \": \" + m.content[0].text.value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
